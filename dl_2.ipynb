{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUgGWEPgJIBT"
      },
      "outputs": [],
      "source": [
        "# Environment Set-Up\n",
        "%%capture\n",
        "!gdown 1YS6NdHvEQb19rTZL6RI-NbAyWy0kX08m\n",
        "!unzip final_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgz2isZ-HuXn",
        "outputId": "2f2d30c6-4c7f-4b7d-8a19-544f61049413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xixoF-tEG0m9"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 2e-4\n",
        "FEATURES = 64\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2\n",
        "IMG_SIZE = 256\n",
        "CHANNELS = 3\n",
        "NUM_EPOCHS = 35\n",
        "\n",
        "# Paths\n",
        "TRAIN_PATH = '/content/final_dataset/train'\n",
        "VAL_PATH = '/content/final_dataset/val'\n",
        "CHECKPOINT_PATH = '/content/drive/MyDrive/Weights'\n",
        "\n",
        "# Loss Functions\n",
        "BCE_LOSS = nn.BCEWithLogitsLoss()\n",
        "L1_LOSS = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5_7mk413Xbk"
      },
      "outputs": [],
      "source": [
        "# Progress Bars\n",
        "bars = {\n",
        "    'epoch': None,\n",
        "    'loading': None,\n",
        "    'training': None,\n",
        "    'validation': None\n",
        "}\n",
        "\n",
        "def update_bar(name, total=None, progress=0, desc='', unit='', position=None, postfix=None):\n",
        "    global bars\n",
        "    clear_output()\n",
        "    if bars[name] is None:\n",
        "        bars[name] = tqdm(total=total, desc=desc, unit=unit, leave=False, position=position, postfix=postfix)\n",
        "    else:\n",
        "        bars[name].update(progress - bars[name].n)\n",
        "        if desc!='': bars[name].set_description(desc)\n",
        "        if postfix: bars[name].set_postfix(postfix)\n",
        "\n",
        "    # Print all bars\n",
        "    for bar in bars.values():\n",
        "        if bar is not None:\n",
        "            print(bar)\n",
        "\n",
        "def close_bar(name):\n",
        "    global bars\n",
        "    if bars[name] is not None:\n",
        "        bars[name].close()\n",
        "        bars[name] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3meLyUz1HKdj"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.gt_dir = os.path.join(self.root_dir, \"GT\")\n",
        "        self.hazy_dir = os.path.join(self.root_dir, \"hazy\")\n",
        "        self.gt_filenames = sorted(os.listdir(self.gt_dir))\n",
        "        self.hazy_filenames = sorted(os.listdir(self.hazy_dir))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.gt_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        gt_name = os.path.join(self.gt_dir, self.gt_filenames[idx])\n",
        "        gt_image = Image.open(gt_name).convert(\"RGB\")\n",
        "\n",
        "        hazy_name = os.path.join(self.hazy_dir, self.hazy_filenames[idx])\n",
        "        hazy_image = Image.open(hazy_name).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            gt_image = self.transform(gt_image)\n",
        "            hazy_image = self.transform(hazy_image)\n",
        "\n",
        "        return gt_image, hazy_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er-EqoayUvwS"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItFrqIbMHXBc"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=CHANNELS*2, features=[64, 128, 256, 512]):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layers = []\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features[0], kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            self.layers.append(self._block(in_channels, feature, stride=1 if feature == features[-1] else 2))\n",
        "            in_channels = feature\n",
        "\n",
        "        self.layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1))\n",
        "\n",
        "        # Initialize weights using He initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "\n",
        "        self.model = nn.Sequential(*self.layers)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    def _block(self, in_channels, out_channels, stride):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # Concatenate the hazy image (x) and ground truth image (y) along the channel dimension\n",
        "        x = torch.cat([x, y], dim=1)\n",
        "        x = self.initial(x)\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def train_step(self, x, y):\n",
        "        self.train()\n",
        "        # Concatenate the hazy image (x) and ground truth image (y) along the channel dimension\n",
        "        disc_input = torch.cat([x, y], dim=1)\n",
        "\n",
        "        disc_output = self.forward(x, y)\n",
        "        disc_loss = BCE_LOSS(disc_output, torch.ones_like(disc_output))\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        disc_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return disc_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cew5DEd0TBwK"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, leaky=True, use_dropout=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "              if down else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2) if leaky else nn.ReLU(),\n",
        "        )\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZdXRqxSHYt1"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=CHANNELS, features=FEATURES):\n",
        "        super().__init__()\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2))\n",
        "\n",
        "        self.down1 = Block(features*1, features*2, down=True, leaky=True, use_dropout=False)\n",
        "        self.down2 = Block(features*2, features*4, down=True, leaky=True, use_dropout=False)\n",
        "        self.down3 = Block(features*4, features*8, down=True, leaky=True, use_dropout=False)\n",
        "        self.down4 = Block(features*8, features*8, down=True, leaky=True, use_dropout=False)\n",
        "        self.down5 = Block(features*8, features*8, down=True, leaky=True, use_dropout=False)\n",
        "        self.down6 = Block(features*8, features*8, down=True, leaky=True, use_dropout=False)\n",
        "\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(features*8, features*8, 4, 2, 1), nn.ReLU())\n",
        "\n",
        "        self.up1 = Block(features*8*1, features*8, down=False, leaky=False, use_dropout=True)\n",
        "        self.up2 = Block(features*8*2, features*8, down=False, leaky=False, use_dropout=True)\n",
        "        self.up3 = Block(features*8*2, features*8, down=False, leaky=False, use_dropout=True)\n",
        "        self.up4 = Block(features*8*2, features*8, down=False, leaky=False, use_dropout=False)\n",
        "        self.up5 = Block(features*8*2, features*4, down=False, leaky=False, use_dropout=False)\n",
        "        self.up6 = Block(features*4*2, features*2, down=False, leaky=False, use_dropout=False)\n",
        "        self.up7 = Block(features*2*2, features*1, down=False, leaky=False, use_dropout=False)\n",
        "\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # Initialize weights using He initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "        self.scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "\n",
        "        return self.final_up(torch.cat([up7, d1], 1))\n",
        "\n",
        "    def train_step(self, x, y):\n",
        "        self.train()\n",
        "        y_fake = self.forward(x)\n",
        "        gen_loss = L1_LOSS(y_fake, y)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        gen_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return gen_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E08B7Ad8t95h"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(gen, disc, epoch):\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_PATH, f\"checkpoint_epoch_{epoch}.pth.tar\")\n",
        "    torch.save({'epoch': epoch,\n",
        "                'gen_state_dict': gen.state_dict(),\n",
        "                'disc_state_dict': disc.state_dict()},\n",
        "               checkpoint_path)\n",
        "    print(f\"Saved checkpoint at epoch {epoch}\")\n",
        "\n",
        "\n",
        "def load_checkpoint(model):\n",
        "    checkpoint_files = [f for f in os.listdir(CHECKPOINT_PATH) if f.endswith('.tar')]\n",
        "    if not checkpoint_files:\n",
        "        start_epoch = 0\n",
        "\n",
        "    # Find the latest checkpoint file\n",
        "    latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_PATH, latest_checkpoint)\n",
        "\n",
        "    # Load the checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    print(f\"Loaded checkpoint '{latest_checkpoint}' (epoch {checkpoint['epoch']})\")\n",
        "    return model, start_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xVrn7FR2lpD"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(gen, disc):\n",
        "    checkpoint_files = [f for f in os.listdir(CHECKPOINT_PATH) if f.endswith('.tar')]\n",
        "    if not checkpoint_files:\n",
        "        start_epoch = 0\n",
        "        print(\"No checkpoint files found in the directory.\")\n",
        "        return gen, disc, start_epoch\n",
        "\n",
        "    # Find the latest checkpoint file\n",
        "    latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_PATH, latest_checkpoint)\n",
        "\n",
        "    # Load the checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    gen.load_state_dict(checkpoint['gen_state_dict'])\n",
        "    disc.load_state_dict(checkpoint['disc_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    print(f\"Loaded checkpoint '{latest_checkpoint}' (epoch {checkpoint['epoch']})\")\n",
        "    return gen, disc, start_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfgs6v93yQXx"
      },
      "outputs": [],
      "source": [
        "def validate_epochs(generator, val_loader):\n",
        "    generator.eval()\n",
        "    psnr_values = []\n",
        "    ssim_values = []\n",
        "\n",
        "    with tqdm(total=len(val_loader), desc='Validation') as pbar:\n",
        "        for batch_idx, (input_data, target_data) in enumerate(val_loader):\n",
        "            input_data = input_data.to(DEVICE)\n",
        "            target_data = target_data.to(DEVICE)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output_data = generator(input_data)\n",
        "\n",
        "                # Compute PSNR\n",
        "                output_data_np = output_data.clamp(0, 1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "                target_data_np = target_data.clamp(0, 1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "                psnr_batch = np.mean([psnr(target_data_np[i], output_data_np[i]) for i in range(output_data_np.shape[0])])\n",
        "                psnr_values.append(psnr_batch)\n",
        "\n",
        "                # Compute SSIM\n",
        "                output_data_np = np.transpose(output_data_np, (0, 3, 1, 2))\n",
        "                target_data_np = np.transpose(target_data_np, (0, 3, 1, 2))\n",
        "                for i in range(output_data_np.shape[0]):\n",
        "                    ssim_value = ssim(output_data_np[i], target_data_np[i], multichannel=True)\n",
        "                    ssim_values.append(ssim_value)\n",
        "\n",
        "                # Update progress bar\n",
        "                pbar.update(1)\n",
        "                pbar.set_postfix({'PSNR': np.mean(psnr_values), 'SSIM': np.mean(ssim_values)})\n",
        "\n",
        "    avg_psnr = np.mean(psnr_values)\n",
        "    avg_ssim = np.mean(ssim_values)\n",
        "    print(f'Validation - Avg PSNR: {avg_psnr:.2f}, Avg SSIM: {avg_ssim:.4f}')\n",
        "\n",
        "    return avg_psnr, avg_ssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik6YXDCS90uO",
        "outputId": "21edad6e-537c-487d-aa28-437e93735f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoint files found in the directory.\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "train_dataset = ImageDataset(root_dir=TRAIN_PATH, transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "val_dataset = ImageDataset(root_dir=VAL_PATH, transform=val_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "generator = Generator().to(DEVICE)\n",
        "discriminator = Discriminator().to(DEVICE)\n",
        "\n",
        "generator, discriminator, start_epoch = load_checkpoint(generator, discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZUyvxiK1YqD",
        "outputId": "095cd820-051d-427b-881d-4239464b9eb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Epoch 1: : 257 [1:36:43, 20.87s/, Generator Loss=0.28, Discriminator Loss=0.000505]\u001b[A\n",
            "Training Epoch 1: : 257 [1:36:43, 20.87s/, Generator Loss=0.28, Discriminator Loss=0.000505]\u001b[A\n",
            "Training Epoch 1: : 257 [1:36:43, 20.87s/, Generator Loss=0.317, Discriminator Loss=0.000525]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35: : 1 [1:37:11, 5831.06s/]\n",
            "Training Epoch 1: : 257 [1:36:43, 20.87s/, Generator Loss=0.317, Discriminator Loss=0.000525]\n"
          ]
        }
      ],
      "source": [
        "update_bar('epoch', desc=f'Epoch', total=NUM_EPOCHS)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "    update_bar('epoch', progress=epoch+1, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "\n",
        "    # Training\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    for batch_idx, (gt_images, hazy_images) in enumerate(train_loader):\n",
        "        gt_images = gt_images.to(DEVICE)\n",
        "        hazy_images = hazy_images.to(DEVICE)\n",
        "\n",
        "        disc_loss = discriminator.train_step(hazy_images, gt_images)\n",
        "        gen_loss = generator.train_step(hazy_images, gt_images)\n",
        "\n",
        "        update_bar('training', progress=batch_idx+1, desc=f'Training Epoch {epoch+1}',\n",
        "                   postfix={'Generator Loss': gen_loss, 'Discriminator Loss': disc_loss})\n",
        "\n",
        "    close_bar('training')\n",
        "    # Validation\n",
        "    avg_psnr, avg_ssim = validate_epochs(generator, val_loader)\n",
        "    # Save checkpoint after each epoch\n",
        "    save_checkpoint(generator, discriminator, epoch)\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}